{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09wFQqjeXMbS"
   },
   "source": [
    "# NLP Individual CourseWork \n",
    "## Name-Vipul Mishra\n",
    "## URN-6657466\n",
    "## Topic- Toxic Comment Classifier\n",
    "Problem Statment - In this Experiment, the challenge is to build a multilabeled model which will detect variety of toxic commments like threats, obscenity, insults, and identity-based hate. Iâ€™ll be using a dataset of comments which i have taken from kaggle. Implementing and Improvements to the current model will hopefully help online discussion become more productive,respectful and less toxic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2qWHxYiaQUX"
   },
   "source": [
    "##Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_D6a48LYEmA",
    "outputId": "6f69cd35-7457-4b4b-d615-aaee7825b772"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'joblib' from 'sklearn.externals' (/opt/anaconda3/lib/python3.8/site-packages/sklearn/externals/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-439543bb1414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (/opt/anaconda3/lib/python3.8/site-packages/sklearn/externals/__init__.py)"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os    #Operating System Library\n",
    "import nltk  #natural language Library\n",
    "import re    #Regular Expression Library\n",
    "import gensim ##Tokenization Library\n",
    "import spacy  ##Lemmatize\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np \n",
    "import time \n",
    "import string \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAtDneVbLv0B"
   },
   "source": [
    "# Loading DataSet and Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MI3iFyLDPzKd",
    "outputId": "8ffabec4-c4ed-497f-ab39-919573e2ead8"
   },
   "outputs": [],
   "source": [
    "#Read data into train_df \n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Printing Head to view \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC6AUWJD_1fi",
    "outputId": "8d1dfd9e-cfaa-4cbf-c44a-ee16e795fa49"
   },
   "outputs": [],
   "source": [
    "rowSums = train.iloc[:,2:].sum(axis=1)\n",
    "clean_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "total=len(train)\n",
    "clean_comments=clean_count\n",
    "comment_labels=total-clean_comments\n",
    "\n",
    "print(\"Total number of comments = \",total)\n",
    "print(\"Comments without label= \",clean_comments)\n",
    "print(\"Comments with labels =\",comment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "4DiqlDScP5JD",
    "outputId": "af27db1d-bca8-4617-fb58-b6a6e14842eb"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmay3rE-QAFP",
    "outputId": "d4124f0d-9205-4869-eeaf-6345e6f2b5ce"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_hyQ9rPigOr",
    "outputId": "10315cb5-5d2f-4e73-c648-b127eceabefd"
   },
   "outputs": [],
   "source": [
    "#Checking for missing values or not \n",
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44u8x9Ghae-Y"
   },
   "source": [
    "##Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "id": "PnmyVWkZo76b",
    "outputId": "68207f37-a64d-4bfe-e5cb-b35ce56c78c9"
   },
   "outputs": [],
   "source": [
    "### Bar Plot \n",
    "categories = list(train.columns.values)\n",
    "categories = categories[2:]\n",
    "print(categories)\n",
    "sns.set(font_scale = 2)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "ax= sns.barplot(categories, train.iloc[:,2:].sum().values)\n",
    "\n",
    "plt.title(\"Total Number of Comments in Each Label\", fontsize=24)\n",
    "plt.ylabel('Number of comments', fontsize=18)\n",
    "plt.xlabel('Label Type ', fontsize=18)\n",
    "\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = train.iloc[:,2:].sum().values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9hQNpVIg2zw"
   },
   "source": [
    "From the above the bar plot we can clearly see that the current dataset we have is unbalanced as most of the comments fall under 'Toxic' Label.\n",
    "We can have one more experimental setup by dropping the 'Toxic' Label which will make the dataset more balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "daICszV5QVRK",
    "outputId": "cf20bf2e-4097-43d9-ce30-1e2bbb2096b6"
   },
   "outputs": [],
   "source": [
    "counts = []\n",
    "for category in categories:\n",
    "    counts.append((category, train [category].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number of comments'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "v2sWRzum1Lex",
    "outputId": "c991b685-1806-4411-b916-91d1a4d6f8bd"
   },
   "outputs": [],
   "source": [
    "Sums = train.iloc[:,2:].sum(axis=1)\n",
    "multiLabel_counts = Sums.value_counts()\n",
    "multiLabel_counts = multiLabel_counts.iloc[1:]\n",
    "\n",
    "sns.set(font_scale = 2)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "ax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n",
    "\n",
    "plt.title(\"Comments having multiple labels \")\n",
    "plt.ylabel('Number of comments', fontsize=18)\n",
    "plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "rects = ax.patches\n",
    "labels = multiLabel_counts.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaHwAL_ohqe-"
   },
   "source": [
    "'Comments Having multiple comments' Bar Graph shows that we have very less comments which falls under all 6 Labels and majority of the comments falls under any of the one label only.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "udvPcVJ_zOA6",
    "outputId": "8fa2201a-5949-4168-c14a-674e588eac07"
   },
   "outputs": [],
   "source": [
    "# Word Cloud for test set\n",
    "\n",
    "words = ' '.join([text for text in train['comment_text'] ])\n",
    "\n",
    "\n",
    "word_cloud = WordCloud(\n",
    "                       width=1600,\n",
    "                       height=800,\n",
    "                       #colormap='PuRd', \n",
    "                       margin=0,\n",
    "                       max_words=500,\n",
    "                       max_font_size=150, min_font_size=30,  # Font size range\n",
    "                       background_color=\"white\").generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.imshow(word_cloud, interpolation=\"bilinear\")\n",
    "plt.title('WordCloud', fontsize = 40)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmGIxX4ZiHcn"
   },
   "source": [
    "Here we have generated a word cloud from the different words mentioned in the 'comment_text' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "dlqGlqEZ5t0Y",
    "outputId": "8a96f814-b875-4cef-e021-5e55238e7acc"
   },
   "outputs": [],
   "source": [
    "target_data = train.drop(['id', 'comment_text'], axis=1)\n",
    "corrMatrix = target_data.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3tWeHFFiiVV"
   },
   "source": [
    "Above generated Heat-map shows the relation between the different labels. For example in this case we have 'severe_toxic' and 'toxic' relationship as 0.31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "-oTQTOVzPWG9",
    "outputId": "22db153e-d728-48b7-8b4c-dc381b7ac93f"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "x=nltk.FreqDist(ToktokTokenizer().tokenize(train['comment_text']))\n",
    "plt.figure(figsize=(16,5))\n",
    "x.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZq12rBRi7VC"
   },
   "source": [
    "Generating Word Frequency Graph from the Pre-Processed DataSet.\n",
    "It shows the frequency of each word throughout the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ykFrJjrynFPi",
    "outputId": "234bdbdd-4205-4271-8a4c-9d645bffb46e"
   },
   "outputs": [],
   "source": [
    "#Sampling the data\n",
    "train = train.sample(1000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "tan9brAplXn4",
    "outputId": "d7980e3a-7255-4ac0-9685-f197e2bbb5df"
   },
   "outputs": [],
   "source": [
    "train_labels = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qHYKQ5hbfaj"
   },
   "source": [
    "#Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJIFd285SMFX"
   },
   "outputs": [],
   "source": [
    " #Defining function for removing punctuation,lowercase, removing hyperlinks\n",
    " def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mb_ADV_YSoQl"
   },
   "outputs": [],
   "source": [
    "# Applying the clean_text on train set\n",
    "\n",
    "train['comment_text_cleaned'] = train['comment_text'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "QU7ZT2jrS8eH",
    "outputId": "711ac30b-ea7a-4dc6-d4d9-62973752deab"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzrlHLFqw_Nb"
   },
   "source": [
    "Tokenizing using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2kmxAUii5ga"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = train.comment_text_cleaned.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn5FUL_Nm7rn"
   },
   "outputs": [],
   "source": [
    "X= []\n",
    "sentences = list(train[\"comment_text_cleaned\"])\n",
    "for texts in sentences:\n",
    "    X.append(clean_text(texts))\n",
    "\n",
    "y = train_labels.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov6RmaMHj5YU"
   },
   "source": [
    "After cleaning the data and converting them into tokens, we are now converting the cleaned tokens into a list from which we will remove all the stops words, generated bigrams and trigrams, lemmatize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BQGg6KvnXx2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFH1LOHRngLG"
   },
   "outputs": [],
   "source": [
    "#Functions for StopWords, n-grams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQjn6hsInoot",
    "outputId": "74268259-067b-49c8-c8bf-ed713b41831c"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_nostops, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:5][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSO7nj4vbyhe"
   },
   "source": [
    "De-Tokenizing for further Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSTS9tXEg7qB",
    "outputId": "8631e526-5f93-4484-efb8-ea721aa81c0a"
   },
   "outputs": [],
   "source": [
    "# de-tokenization\n",
    "detokenized_doc = []\n",
    "clean_df=pd.DataFrame()\n",
    "for i in range(len(data_lemmatized)):\n",
    "    t = ' '.join(data_lemmatized[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "clean_df= detokenized_doc\n",
    "#clean_df=list(clean_df.list()\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXFkrarHb3sE"
   },
   "source": [
    "###Splitting the Data in Train and Test  \n",
    "Splitting is done using 70/30 split as it fairly splits the data into enough train data and test data which further gives us the more precision(accuracy) while testing the model. If the data is splitted as per 75/25 ratio then surely we would have trained our model with more than required training data but then it would have impacted our volume of test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STMHWAZrjM1Z"
   },
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_df,train_labels, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJDbw6pd5Rv8"
   },
   "source": [
    "# Experiment Setup 1\n",
    "\n",
    "> In this experimental setup i have opted for CountVector for feature vectorization and then implemented the Binary Relevance Model and found out the accuracy and other metrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82GqGAUd5hv_"
   },
   "source": [
    "Vectorizing using CountVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3oZA18GzpcT",
    "outputId": "efad36e3-0c94-486d-c3ee-449896c8fb15"
   },
   "outputs": [],
   "source": [
    "##Using CountVectorizer to Vectorize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# List of text documents\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Tokenize and build vocab\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "print(\"Vocab for X_train:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "vectorizer.fit(X_test)\n",
    "print(\"Vocab for X_test:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# Encode document\n",
    "cv_x_train = vectorizer.transform(X_train)\n",
    "cv_x_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0inENvEpcgro"
   },
   "source": [
    "Implementing Binary Relevance Model on features using CountVector method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F__sy8vzBXOW",
    "outputId": "adcb90b0-b1a3-4cc5-860f-7afb66c301e7"
   },
   "outputs": [],
   "source": [
    "#Install required packages \n",
    "!pip install Cython\n",
    "!pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3NUBGTgHlki",
    "outputId": "c01b9052-4c3b-4d4d-d022-a52121267a33"
   },
   "outputs": [],
   "source": [
    "##### Binary Relevance(GaussianNB)using CountVector \n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(cv_x_train, y_train)\n",
    "# predict\n",
    "predictions_br_cv = classifier.predict(cv_x_test)\n",
    "# accuracy\n",
    "accuracy_br_cv = accuracy_score(y_test,predictions_br_cv)\n",
    "print(\"Accuracy = \",accuracy_br_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vb-VQ0DxI9Cl",
    "outputId": "ded36bf7-7e33-4a2e-8f35-ccb07211ce0f"
   },
   "outputs": [],
   "source": [
    "#F1 Score Binary Relevance\n",
    "f1=f1_score(y_test, predictions_br_cv,average=None)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJDBahEFJHCb",
    "outputId": "65f9434e-e650-42e8-94d0-3346d53510f4"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_br_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FbIAUGiXMDk"
   },
   "source": [
    "# Experiment Setup 2\n",
    "\n",
    "> Here I have opted for TF-IDFVectorizer for feature vectorization and generated N-grams by altering the hyperparameters in TFIDFVectorizer, further i have implemented Binary Relevance Model(GaussianNB) for each of the n-gram (1-gram,2-gram,3-gram) and identified the accuracy for each model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa_mXiEjXDYn"
   },
   "source": [
    "## Vectorizing using TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJ2AmxfbE7KQ"
   },
   "outputs": [],
   "source": [
    "#Vectorizing using Tf-Idf Uni-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word',max_features=40000, ngram_range=(1,1))\n",
    "vectorizer.fit(X_train)\n",
    "X_train_uni = vectorizer.transform(X_train)\n",
    "X_test_uni = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyD1coB0ZuB5"
   },
   "outputs": [],
   "source": [
    "#Vectorizing using Tf-Idf Bi-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word',max_features=40000, ngram_range=(1,2))\n",
    "vectorizer.fit(X_train)\n",
    "X_train_bi = vectorizer.transform(X_train)\n",
    "X_test_bi = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPob0LBHZwfS"
   },
   "outputs": [],
   "source": [
    "#Vectorizing using Tf-Idf Tri-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word',max_features=40000, ngram_range=(1,2))\n",
    "vectorizer.fit(X_train)\n",
    "X_train_tri = vectorizer.transform(X_train)\n",
    "X_test_tri = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lMU4uBzYR7H"
   },
   "source": [
    "# Binary Relevance Model\n",
    "Implementing using TF-IDF Vectorizer for 1-gram,2-gram and 3-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iS0jmekdHUo"
   },
   "source": [
    "Uni-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7ui2PxAb4Ba",
    "outputId": "7d6a35c3-1227-4a70-ae5f-59d41f034e3a"
   },
   "outputs": [],
   "source": [
    "##### using binary relevance with unigram\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train_uni, y_train)\n",
    "# predict\n",
    "predictions_br_uni = classifier.predict(X_test_uni)\n",
    "# accuracy\n",
    "accuracy_br_uni = accuracy_score(y_test,predictions_br_uni)\n",
    "print(\"Accuracy = \",accuracy_br_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HYYKBfDe4DH",
    "outputId": "ba32607f-8943-4397-e26b-bc0d45469b30"
   },
   "outputs": [],
   "source": [
    "#F1 Score Binary Relevance TF-IDF Unigram\n",
    "f1_score(y_test, predictions_br_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VE7E6mPCwhaw",
    "outputId": "6fd34c27-ba5f-482d-824b-456bfb5429dc"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_br_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkkYC-1WYwtr"
   },
   "source": [
    "Bi-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaPR5AO63fTd",
    "outputId": "68053c0c-d327-4695-82de-19b9760a02da"
   },
   "outputs": [],
   "source": [
    "##### using binary relevance with bigram\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train_bi, y_train)\n",
    "# predict\n",
    "predictions_br_bi = classifier.predict(X_test_bi)\n",
    "# accuracy\n",
    "accuracy_br_bi = accuracy_score(y_test,predictions_br_uni)\n",
    "print(\"Accuracy = \",accuracy_br_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMV8cvvzcfIr",
    "outputId": "0f57b988-80bc-4819-9e6c-2ae0a3e7c13f"
   },
   "outputs": [],
   "source": [
    "##F1 Score Binary Relevance-bigram\n",
    "f1_score(y_test, predictions_br_bi,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kU5JPsu5FKFd",
    "outputId": "c86bab5d-af7a-4b78-c3ca-1628e5019419"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_br_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVYSO5d3zkTy"
   },
   "source": [
    "Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4G35TZyJcDO7",
    "outputId": "95ccca5d-e068-402f-823c-f43e1e1e3417"
   },
   "outputs": [],
   "source": [
    "##### using binary relevance with trigram\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train_tri, y_train)\n",
    "# predict\n",
    "predictions_br_tri = classifier.predict(X_test_tri)\n",
    "# accuracy\n",
    "accuracy_br_tri = accuracy_score(y_test,predictions_br_tri)\n",
    "print(\"Accuracy = \",accuracy_br_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJlYC_2bfNhW",
    "outputId": "4457b2f5-c3bd-4f93-9b8b-c0c46d6a1423"
   },
   "outputs": [],
   "source": [
    "#F1 Score Binary Relevance-trigram\n",
    "f1_score(y_test, predictions_br_tri,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ttb4fnuaQw7",
    "outputId": "3e913339-dfe9-4a9f-f3c6-0295118e4b62"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_br_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFhiI--NnxBe"
   },
   "source": [
    "From the accuracy score of 1-gram, 2-gram and 3-gram, we can easily say that 1-gram and 2-gram gives same accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJHyHHE8lsHR"
   },
   "source": [
    "#Experiment Setup 3 \n",
    "\n",
    "\n",
    "> In experiment 3, i have used Classifier Chains model using different Algorithm such as SVC, Logistic Regression and RandomForest Classifier. \n",
    "Also, identified the accuracy score and other metrices for each of the models implemented for comparison. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYup2JeqcU4q"
   },
   "source": [
    "\n",
    "# Classifier Chains Model, F1 Score and Confusion Matrix\n",
    "Implemented Using different classifer models SVC,Logistic Regression, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj0DtICycg3C"
   },
   "source": [
    "Classifier Chain with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZIYnsqspxcR",
    "outputId": "a2447c52-75ba-4fb4-d5a5-415df78ad175"
   },
   "outputs": [],
   "source": [
    "#### Using Classifier Chains with SVC\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(SVC())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train_uni, y_train)\n",
    "# predict\n",
    "predictions_cc_uni = classifier.predict(X_test_uni)\n",
    "# accuracy\n",
    "accuracy_cc_svc = accuracy_score(y_test,predictions_cc_uni)\n",
    "print(\"Accuracy = \",accuracy_cc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDVXIUk9kAS-",
    "outputId": "a24d38f5-94ee-4849-92e3-abc7a73e3b3b"
   },
   "outputs": [],
   "source": [
    "#F1 Score Classifier Chains SVC\n",
    "f1_score(y_test, predictions_cc_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RgXK5kyddCe",
    "outputId": "32e6aea2-e0ad-466c-cad4-c84a370b8b30"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_cc_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQDYQjxDdy4W"
   },
   "source": [
    "Classifier Chain with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeO6UYGYh_ns",
    "outputId": "2db68090-97ff-43f1-e1af-552af72215e3"
   },
   "outputs": [],
   "source": [
    "#### Using Classifier Chains with LogisticRegression\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train_uni, y_train)\n",
    "# predict\n",
    "predictions_cc_lr = classifier.predict(X_test_uni)\n",
    "# accuracy\n",
    "accuracy_cc_lr = accuracy_score(y_test,predictions_cc_lr)\n",
    "print(\"Accuracy = \",accuracy_cc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ik_SMKJ-kapv",
    "outputId": "002ed3da-afa8-492f-9130-82b79fac8883"
   },
   "outputs": [],
   "source": [
    "#F1 Score Classifier Chains Logistic Regression\n",
    "f1_score(y_test, predictions_cc_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Or39VH4xd62Y",
    "outputId": "bd2ef1f0-6824-4415-e83c-4a908ce7a6ed"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_cc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIqbJJKSeB08"
   },
   "source": [
    "Classifier Chain with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwXypBqGJWwk",
    "outputId": "01ab5fe8-0bbc-4a8f-99ed-a98fb9eae021"
   },
   "outputs": [],
   "source": [
    "#### Using Classifier Chains with RandomForest\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(RandomForestClassifier(n_estimators=100))\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train_uni, y_train)\n",
    "# predict\n",
    "predictions_cc_rfc = classifier.predict(X_test_uni)\n",
    "# accuracy\n",
    "accuracy_cc_rfc = accuracy_score(y_test,predictions_cc_rfc)\n",
    "print(\"Accuracy = \",accuracy_cc_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zh1MmBfQdtAd",
    "outputId": "e719c310-7c11-499e-fd0c-05901fbff2ba"
   },
   "outputs": [],
   "source": [
    "#F1 Score Classifier Chains RandomForest\n",
    "f1_score(y_test, predictions_cc_rfc,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcLFkiIFdylx",
    "outputId": "34a9e1c5-b0e1-451a-9407-308c3b74e8ec"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_cc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTt9KPiGeNqK"
   },
   "source": [
    "# Label Power Set Model, F1 Score and Confusion Matrix\n",
    "Implementing using GaussianNB for 1-gram and 2-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2My_8Y_Dei8F"
   },
   "source": [
    "Uni-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeiytdO6NscP",
    "outputId": "cd8dc8a1-6c58-4b7b-ae45-ce7c8f877b33"
   },
   "outputs": [],
   "source": [
    "# Using Label Powerset Uni-gram\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train_uni, y_train)\n",
    "# predict\n",
    "predictions_lp_ga_uni = classifier.predict(X_test_uni)\n",
    "# accuracy\n",
    "accuracy_lp_ga_uni = accuracy_score(y_test,predictions_lp_ga_uni)\n",
    "print(\"Accuracy = \",accuracy_lp_ga_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwAhtC1GeKev",
    "outputId": "f61293e9-7443-4e4b-c444-ce1f3428a073"
   },
   "outputs": [],
   "source": [
    "#F1 Score Label Powerset unigram\n",
    "f1_score(y_test, predictions_lp_ga_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en2cOMTLeOjZ",
    "outputId": "0a3eeed9-498f-4fdc-9109-b91de8805445"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_lp_ga_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BDld035eRGo"
   },
   "source": [
    "Bi-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udplM5U0H7cD",
    "outputId": "f6ad4dd1-3f26-4757-8b6a-d0849b065653"
   },
   "outputs": [],
   "source": [
    "# Using Label Powerset Bi-gram\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train_bi, y_train)\n",
    "# predict\n",
    "predictions_lp_ga_bi = classifier.predict(X_test_bi)\n",
    "# accuracy\n",
    "accuracy_lp_ga_bi = accuracy_score(y_test,predictions_lp_ga_bi)\n",
    "print(\"Accuracy = \",accuracy_lp_ga_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkPFymrhmgox",
    "outputId": "19f2724d-89d7-4f91-928f-67689a7c50b7"
   },
   "outputs": [],
   "source": [
    "#F1 Score Label Powerset unigram\n",
    "f1_score(y_test, predictions_lp_ga_bi,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32Rs8JGaednD",
    "outputId": "1b2c6582-43ae-4b3d-8fd4-37e32e95b52b"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_lp_ga_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuQaHHTambKY"
   },
   "source": [
    "#Experiment Setup 4\n",
    "\n",
    "> In setup 4 i have used Adapted Algorithm model using MLkNN Algorithm with different 'K' values to give accuracy score and then compare the two to find out the better one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lznm_2bAezsG"
   },
   "source": [
    "# Adapted Algorithm Model, F1 Score and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJUpiPz4e75O"
   },
   "source": [
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOl-lryhqY8g",
    "outputId": "5a16579d-ae23-475e-8958-bf77578db80f"
   },
   "outputs": [],
   "source": [
    "###Using Adapted Algo for Unigram\n",
    "\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=5)\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "x_train = lil_matrix(X_train_bi).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(X_test_bi).toarray()\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "predictions_aa_mlknn_bi = classifier_new.predict(x_test)\n",
    "# accuracy\n",
    "accuracy_aa_mlknn_uni = accuracy_score(y_test,predictions_aa_mlknn_bi)\n",
    "print(\"Accuracy = \",accuracy_aa_mlknn_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UssdZgp0n3Dx",
    "outputId": "efc69520-b92a-48de-8520-351d99e76b79"
   },
   "outputs": [],
   "source": [
    "#F1 Score Adopted Algo unigram\n",
    "f1_score(y_test, predictions_aa_mlknn_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZSHwwV6fIY0",
    "outputId": "5727b893-19f8-4ac2-ebda-a00da8c56eb4"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_aa_mlknn_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpMEW0NkmXjP"
   },
   "source": [
    "K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUWbb7ppOKMB",
    "outputId": "25da734c-5025-469c-e12e-33184a98d009"
   },
   "outputs": [],
   "source": [
    "###Using Adapted Algo for Bi-gram\n",
    "\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=10)\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "x_train = lil_matrix(X_train_bi).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(X_test_bi).toarray()\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "predictions_aa_mlknn_bi = classifier_new.predict(x_test)\n",
    "# accuracy\n",
    "accuracy_aa_mlknn_bi = accuracy_score(y_test,predictions_aa_mlknn_bi)\n",
    "print(\"Accuracy = \",accuracy_aa_mlknn_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QsVOqzUeZd-",
    "outputId": "d0d095d8-eca9-4a0e-97ff-d5074c7db24d"
   },
   "outputs": [],
   "source": [
    "#F1 Score Adopted Algo Bi-gram\n",
    "f1_score(y_test, predictions_aa_mlknn_uni,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxQiHuo4ecVt",
    "outputId": "f4a3ed75-e522-45d4-d71b-f0312ce90220"
   },
   "outputs": [],
   "source": [
    "##Making Confusion Matrix for the model\n",
    "multilabel_confusion_matrix(y_test, predictions_aa_mlknn_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gbjO4Y4oz4Y"
   },
   "source": [
    "From either K=5 or K=10, we have acheived same accuracy, making the change irrelevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlTezHR1enRe"
   },
   "source": [
    "# Comparing Accuracy Achieved from using different Models and different Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5ldvwrNOxlf",
    "outputId": "a81be1ea-eebd-4df8-8bf8-0d31a79f284f"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for Count Vector = \",accuracy_br_cv)\n",
    "print(\" \")\n",
    "print(\"Accuracy for BR Models(1-gram) = \",accuracy_br_uni)\n",
    "print(\"Accuracy for BR Models(2-gram) = \",accuracy_br_bi)\n",
    "print(\"Accuracy for BR Models(3-gram) = \",accuracy_br_tri)\n",
    "print(\" \")\n",
    "print(\"Accuracy for ClassifierChain(SVC) = \",accuracy_cc_svc)\n",
    "print(\"Accuracy for ClassifierChain(lr) = \",accuracy_cc_lr)\n",
    "print(\"Accuracy for ClassifierChain(rfc) = \",accuracy_cc_rfc)\n",
    "print(\" \")\n",
    "print(\"Accuracy for LabelPowerset(Gaussian_1-gram) = \",accuracy_lp_ga_uni)\n",
    "print(\"Accuracy for LabelPowerset(Gaussian_2-gram) = \",accuracy_lp_ga_bi)\n",
    "print(\" \")\n",
    "print(\"Accuracy for AdaptedAlgo(MLKnn_1-gram) = \",accuracy_aa_mlknn_uni)\n",
    "print(\"Accuracy for AdaptedAlgo(MLKnn_2-gram) = \",accuracy_aa_mlknn_bi)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh-Hc44_pyck"
   },
   "source": [
    "After performing all the different experiments using different Feature Vectorization and using different ML models with different algorithms and by analysing the accuracy score for each experiment setup, ClassifierChain Model has turned out to be the better choice for implementing and addressing the multi-label problem at hand. \n",
    "Although the accuracy score from different setups is not varying much in some case but the F1 Score achieved is quite low, this arises the need for retraining the model using different parameters or algorithm altogther. \n",
    "Further experiments can be done using different models other than the one used in above setups. \n",
    "\n",
    "By doing multiple different experiments to acheive best accuracy, I have learnt so many ways for implementing an NLP Model. Experimenting with variety of setups helps getting familiar with this NLP module and opens up the possibility for further evaluation and learning. This experiment has helped me in upscaling my critical thinking skill which will be an added advantage in forthcoming ML Models."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Experiment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
